# Chronicle Queue to kdb+ Adapter

## What is Chronicle Queue?

This memory mapped file is also used for exceptionally fast inter-process communication (IPC) without affecting your system performance. This is especially useful when there is a need to transfer large amounts of data, its ideal for transferring data between processes very quickly on the same server or across the network. There is no Garbage Collection (GC) as everything is done off heap.

### Features

* Low-latency, high-performance Java and C++ software
* No data loss; stores every value instead of replacing them
* No GC as everything is done off-heap
* Persistence to disk through memory mapped files
* IPC between Java processes or between threads in a Java process
* Simple API for ease of use
* Replay-ability of all your inputs and outputs
* Concurrent writers across processes on the same machine
* Embedded performance in all processes
* Data is written synchronously to ensure no data is lost
* Data is read less than a microsecond after it is written

### How does it work?

Chronicle uses a memory mapped file to continuously journal messages, Chronicle's file-based storage will slowly grow in size as more data is written to the queue, the size of the queue can exceed your available memory, you are only constrained by the amount of disk space you have on your server. Chronicle writes data directly into off-heap memory which is shared between java processes on the same server.

Chronicle is very fast, it is able to write and read a message in just two microseconds with no garbage. Typically at the end of each day, you archive the queue and start the next day with a fresh empty queue.

More info: https://chronicle.software/libraries/queue/

## What is kdb+ Time Series Database?

Kdb+, from Kx, is / has:
* a high-performance cross-platform historical time-series columnar database
* an in-memory compute engine
* a real-time streaming processor
* an expressive query and programming language called q

More info: https://code.kx.com/q/

## Project goal

Create an "adapter" to allow messages arriving on a Chronicle Queue to be inserted into a table in kdb+.

## Scenario

* "Quotes added as messages to a Chronicle Queue should be replicated as entries in the quote table in a kdb+ database."
* Create an Adapter to enable this
	* Quote >> Chronicle Queue >> Adapter >> kdb+

## Components

* Producer
	* Will create Quotes and place as new messages on a named Chronicle Queue.
* Chronicle Queue
	* A file based queue called "quote", addressed via filesystem location e.g. "C:\\ChronicleQueue\\Producer\\quote"
* Adapter
	* Application to read from the queue and write to a kdb+ database table.
* kdb+
	* Destination database containing quote database table and supporting functions to allow data to be added.

## "Quote" message

Messages representing a Quote will be randomly generated by the Producer and added to the Quote queue in the following format:

| Name | Value |
| ------------- |-------------|
| time | 2020.01.24+14:00:16.083Z |
| sym | VOD.L |
| bid | 152 |
| bsize | 42035 |
| ask | 152 |
| assize | 48514 |
| bex | XLON |
| aex | XLON |

## Producer 

The Producer will be configured to connect to a specified queue, the quote queue, and write write a stream of quotes to the queue.

The quotes will be randomly generated as per the format above and will be added to the queue using a Chronicle Queue Appender.

Quotes will then be written to the queue as a "self-describing message". E.g.:
	
	appender.writeDocument(w -> w.write("quote").marshallable(
			m -> m.write("time").dateTime(LocalDateTime.now())
					.write("sym").text("VOD.L")
					.write("bid").float64(152)
					.write("bsize").float64(42035)
					.write("ask").float64(152)
					.write("assize").float64(48514)
					.write("bex").text(XLON)
					.write("aex").text(XLON)
	));	

## Adapter process

<img src="https://user-images.githubusercontent.com/74417594/105519835-cfd9a680-5cd1-11eb-9119-9808371832a7.png" width="900" style="border:5px solid black" />

## Adapter application

The Adapter for our scenario has been built as in Java and can be built out to a jar file.

The application will implement the process above using vendor specific libraries (Chronicle and kdb+) as well as other 3rd party Open Source libraries.

The main classes in the Adapter component are shown here:

<img src="https://user-images.githubusercontent.com/74417594/107047194-738d8100-67bf-11eb-81d9-a0b8eae1230b.png" width="900" style="border:5px solid black" />

### 1. Connect to data source i.e. Chronicle Queue

When the application is started, use Chronicle Queue java library to connect to a queue. This library can be added to a maven project pom.xml file as a dependency:

	<dependency>
		<groupId>net.openhft</groupId>
		<artifactId>chronicle-queue</artifactId>
		<version>5.20.111</version>
	</dependency>
		
The data source / queue should be identified via an external properties file. Chronicle Queues are typically addressed via filesystem location e.g. "C:\\ChronicleQueue\\Producer\\quote"

	chronicle.source=C:\\ChronicleQueue\\Producer\\quote

### 2. Check queue for new messages

Once connected to the data source, use a Chronicle Queue Tailer to read the queue and check for new messages of the configured "type" (adapter.messageType). 
The tailer should be named, based on configuration in an external properties file (adapter.tailerName). 
The tailer should read forward from the last message read when re-started.
When there are no messages to read, the adapter should stop for a configurable period of time (adapter.waitTime.whenNoMsgs).

	adapter.tailerName=quoteTailer
	adapter.messageType=quote
	adapter.waitTime.whenNoMsgs=10000

### 3. Read message data ( -> chronicle obj)

Marshall each quote message that is read by the tailer into a specific POJO representing the chronicle queue quote message.
This will be achieved using a simple Builder component to create an instance of the "Chronicle Quote Message" POJO for each message received.

### 4. Do mapping (chronicle obj -> kdb obj)

Mapstruct allows simple or very complex mapping between source and destination POJO's to be coded quickly as an interface. Mapping is defined in the interface and when the application is built, code is automatically generated to implement the interface. 
Use Mapstruct to map the source Chronicle Quote Message POJO to the destination kdb+ Quote POJO. 

Maven dependency to include Mapstruct:

	<dependency>
		<groupId>org.mapstruct</groupId>
		<artifactId>mapstruct</artifactId>
		<version>1.4.1.Final</version>
	</dependency>

Reference guide: https://mapstruct.org/documentation/stable/reference/html/

### 5. Add kdb msg to current kdb envelope

Rather than send messages to kdb+ one at a time, it is more efficient to batch them together into a single call in a structured Object array. To facilitate this, the application will manage an "envelope" containing the combined data of one or more messages.

### 6. Send data to destination ( -> kdb+)

#### Batching methods

The envelope size will be limited by another configuration parameter:

	kdb.envelope.size=200

As there may be occasions when an envelope may not be full, that will lead to messages having been read from the source queue being "stuck" in the Adapter. To get around this, a Timer will be used to track the amount of time between messages being added to the envelope. 

	kdb.envelope.waitTime=20
	
The parameter above will set the wait time and if that is exceeded, the current envelope will be sent to kdb+ and then reset.

#### kdb+ 

kdb+ provides a java API in a single source file on GitHub. Inclusion in a development project is, therefore, a straightforward matter of including the file with other source code under the package kx, and ensuring it is properly imported and referenced by other classes.

Reference: https://code.kx.com/q/wp/java-api/

The Adapter will use this API to connect to (or check a connection is already open to) a kdb+ database defined in external config e.g.:

	kdb.host=localhost
	kdb.port=5000
	kdb.login=username:password
	kdb.connection-enabled=true

In the kdb+ database there is a quote table defined as:

	.schema.addschema ([]table:`quote;col:`time`chrontime`sym`bid`bsize`ask`asize`bex`aex;coltype:`timestamp`timestamp`symbol`float`float`float`float`symbol`symbol;isnested:000000000b);

and a function ".u.upd" to insert data into the database.

The destination table and function we are using are specified in the external config file also:

	kdb.destination=quote
	kdb.destination.function=.u.upd

To insert entries into the quote table, the adapter uses one of the "ks" methods to send all messages in the current envelope to kdb+:

	kdbConnection.ks(kdbMethod, destinationTable, kdbEnvelope.toObjectArray());

the kdb message data is formatted as Object[] similar to this:

	[chrontime[],sym[],bsize[],ask[],asize[],bex[],aex[]]


## Running the process

### Start the Producer

The Producer component in the repositry has been built to facilitate the generation of Quote messages on the Chronicl Queue. Once running, the Producer component can be started and stopped via endpoints to allow some control and help testing. These can be accessed via the built-in Swagger page, directly with a url or directly through a tool like Postman. E.g.: 

*Send 10 messages at 0 milliseconds intervals (i.e. no wait in between) http://localhost:9090/producer/quoteLoader?Command%3A%20start%2Fstop=start&No.%20to%20generate=10&Interval%20in%20millis=0
* If running a long generation process it can be stopped by sending -- http://localhost:9090/producer/quoteLoader?Command%3A%20start%2Fstop=stop&No.%20to%20generate=0&Interval%20in%20millis=0

The Producer console showing messages being added to the queue:

	2021-02-03 17:14:57.723  INFO 48340 --- [nio-9090-exec-2] c.c.d.p.controllers.ProducerController   : TIMING: Added 10 messages (up to index: 80148384825735) in 0.0110204 seconds
	2021-02-03 17:14:57.723  INFO 48340 --- [nio-9090-exec-2] c.c.d.p.controllers.ProducerController   : *** Successfully executed query

### Start kdb+ instance

If running on a Windows OS, use a cmd prompt / Powershell window and run the following command:

	q dummytp.q -p 5000 -u 1}

should return the "q prompt similar to that below:

	KDB+ 4.0 2020.05.04 Copyright (C) 1993-2020 Kx Systems
	w64/ 4(16)core 16080MB xx yy-zz 172.20.64.1 EXPIRE 2021.11.18 e-mail@address.com KOD #1234567

	q)

Check that the quote table exists and is empty:

	q)quote
	time chrontime sym bid bsize ask asize bex aex
	----------------------------------------------
	q)

### Start the Adapter

Once started, the adapter will connect to the kdb+ database first and then the Chronicle queue.

	....
	Feb 03, 2021 5:16:21 PM com.kdb.adapter.chronicle.ChronicleKdbAdapter processMessages INFO: Starting Chronicle kdb Adapter
	Feb 03, 2021 5:16:21 PM com.kdb.adapter.chronicle.ChronicleKdbAdapter processMessages INFO: Tailer starting at index: 80148384825736
	Feb 03, 2021 5:16:21 PM com.kdb.adapter.chronicle.ChronicleKdbAdapter saveCurrentEnvelope INFO: TIMING: Stored 10 messages (up to index: 80148384825745) in 0.0013226 seconds
	Feb 03, 2021 5:16:21 PM com.kdb.adapter.chronicle.ChronicleKdbAdapter processMessages INFO: Stopping Chronicle kdb Adapter. 10 msgs stored in this cycle (0.083505101 seconds)
	....

Each message read is added to kdb+ and will show in the kdb+ console as follows:

	....
	received message: (".u.upd";`quote;(2021.02.03D17:16:16.318827300 2021.02.03D17:16:16.318827300..
	insert successful
	....

A simple check of the quote table shows that the data has been added:

	q)quote
	time                          chrontime                     sym     bid  bsiz..
	-----------------------------------------------------------------------------..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:25.958331200 VOD.L   154  2661..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:25.962331600 VOD.L   152  1636..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:25.964324800 HEIN.AS 101  2706..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:25.964324800 HEIN.AS 101  3746..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:25.964324800 JUVE.MI 1232 2809..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:25.965327400 HEIN.AS 101  4875..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:25.965327400 HEIN.AS 100  1663..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:25.966337200 JUVE.MI 1238 3975..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:25.966337200 JUVE.MI 1232 4766..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:25.967731000 VOD.L   155  2874..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:38.124967100 HEIN.AS 102  2200..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:38.234965000 HEIN.AS 104  2516..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:38.344966400 VOD.L   153  2304..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:38.456509300 JUVE.MI 1230 4990..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:38.566501900 JUVE.MI 1238 3918..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:38.676502900 JUVE.MI 1237 2580..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:38.787779900 JUVE.MI 1237 2119..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:38.898779900 VOD.L   154  3414..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:39.010326700 JUVE.MI 1231 1613..
	2021.02.03D17:16:01.757618000 2021.02.03D16:38:39.121323400 VOD.L   152  2283..
	..

NOTE: The "time" column is the inserted time kdb generated and the "chrontime" column is the timestamp value from each message generated by the Producer application.

# Summary

As a reminder, the adapter scenario that was used was:

* "Quotes added as messages to a Chronicle Queue should be replicated as entries in the quote table in a kdb+ database."
* Create an Adapter to enable this
	* Quote >> Chronicle Queue >> Adapter >> kdb+

We now have enabled this by developing an adapter that can process quote messages from a configurable source, that is a Chronicle Queue, and write each message as a new entry in a configurable destination table in a kdb+ database.

# Further considerations

Whilst there are some generic aspects to the adapter that are configurable e.g. source and destination details, there are some parts of the solution that are difficult to generify.

The scenario used was based on our quote messages. The messages were generated in a specific, known format, added to the queue in a specific manner, i.e. as a self-describing message. This allowed the adapter to map known fields from the source message to known fields in the destination object. Finally, the kdb+ table used was structured specifically for quote data.

The quote adapter example that has been completed, should be considered as a base framework to develop further message specific adapters from Chronicle Queue into kdb+. That means for every adapter required there will 

# Possible next steps

Develop the reverse scenario, i.e. quote >> kdb+ >> adapter >> Chronicle queue 
